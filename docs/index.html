<!DOCTYPE html><!--AArsfQyQ1ehliyZcDM_u1--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/4e7ef18dbe1e50ad.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/708dfc0609e1343f.js"/><script src="/_next/static/chunks/079efb4bc77f350c.js" async=""></script><script src="/_next/static/chunks/ea7ab0dba7b47d7c.js" async=""></script><script src="/_next/static/chunks/turbopack-fd6c976a90393a42.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/7dd66bdf8a7e5707.js" async=""></script><script src="/_next/static/chunks/f7a78c382ccb5d83.js" async=""></script><meta name="next-size-adjust" content=""/><title>Complete Object Removal via Object-Effect Attention</title><meta name="description" content="ObjectClear: Complete object removal via object-effect attention with OBER dataset."/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen bg-slate-700 text-white"><section class="py-12 px-4"><div class="max-w-6xl mx-auto text-center"><h1 class="text-4xl md:text-5xl lg:text-6xl font-normal leading-tight mb-8 px-4">PANDORA<br/>Pixel-wise Attention Dissolution<br/>and Latent Guidance<br/>for Zero-Shot Object Removal</h1><div class="text-lg md:text-xl mb-8">Anonymous authors</div><div class="flex flex-wrap items-center justify-center gap-4 mb-12"><a href="#" class="px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors">PDF</a><a href="#" class="px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors">ARXIV</a><a href="https://github.com/padora-research/padora-research.github.io" class="px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors" target="_blank" rel="noopener noreferrer">Code</a></div><div class="max-w-4xl mx-auto bg-gray-100 rounded-lg p-8"><h2 class="text-3xl text-gray-700 font-light mb-6">Demo Video</h2><div class="aspect-video bg-white rounded overflow-hidden"><video class="w-full h-full object-cover" controls="" loop="" muted="" playsInline=""><source src="https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4" type="video/mp4"/>Your browser does not support the video tag.</video></div></div></div></section><section class="py-12 px-4 bg-gray-100 text-gray-900"><div class="max-w-6xl mx-auto"><div class="flex gap-8"><h2 class="text-3xl font-bold uppercase min-w-fit">Abstract</h2><p class="text-lg leading-relaxed">Removing objects from natural images remains a formidable challenge, often hindered by the inability to synthesize semantically appropriate content in the foreground while preserving background integrity. Existing methods often rely on fine-tuning, prompt engineering, or inference-time optimization, yet still struggle to maintain texture consistency, produce rigid or unnatural results, lack precise foreground-background disentanglement, and fail to flexibly handle multiple objectsâ€”ultimately limiting their scalability and practical applicability. In this paper, we propose a zero-shot object removal framework that operates directly on pre-trained text-to-image diffusion modelsâ€”requiring no fine-tuning, no prompts, and no optimization. At the core is our Pixel-wise Attention Dissolution, which performs fine-grained, pixel-wise dissolution of object information by nullifying the most correlated keys for each masked pixel. This operation causes the object to vanish from the self-attention flow, allowing the coherent background context to seamlessly dominate the reconstruction. To complement this, we introduce Localized Attentional Disentanglement Guidance, which steers the denoising process toward latent manifolds that favor clean object removal. Together, Pixel-wise Attention Dissolution and Localized Attentional Disentanglement Guidance enable precise, non-rigid, scalable, and prompt-free multi-object erasure in a single pass. Experiments show our method outperforms state-of-the-art methods even with fine-tuned and prompt-guided baselines in both visual fidelity and semantic plausibility.</p></div></div></section><section class="py-16 px-4 bg-white text-gray-900"><div class="max-w-6xl mx-auto"><h2 class="text-3xl font-bold uppercase text-center mb-6">Object Removal</h2><p class="text-lg text-center mb-6 max-w-4xl mx-auto leading-relaxed">Our object removal model effectively eliminates objects and their effects on the scene from images. Despite being trained on a relatively small counterfactual dataset captured in controlled environments, the model demonstrates remarkable generalization to diverse scenarios, seamlessly removing large objects.</p><div class="bg-blue-50 border border-blue-200 rounded-lg py-4 px-6 mb-8 text-center"><p class="text-blue-900 flex items-center justify-center gap-2"><span class="text-2xl">ðŸ‘†</span><span>Click on any image to see results</span></p></div><div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-6 mb-12"><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/vercel.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/next.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Boat House" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Boat House</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/globe.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/window.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Hot Air Balloon" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Hot Air Balloon</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/file.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/globe.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Helicopter" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Helicopter</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/next.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/vercel.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Tiger" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Tiger</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/window.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/file.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Dog on Beach" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Dog on Beach</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/vercel.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/next.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Whiskey Glass" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Whiskey Glass</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/globe.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/window.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Giraffe" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Giraffe</figcaption></figure><figure class="relative overflow-hidden rounded bg-zinc-100 dark:bg-zinc-900 " style="aspect-ratio:1.7777777777777777"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/vercel.svg"/><div class="absolute inset-0 overflow-hidden" style="width:0"><img alt="" loading="lazy" decoding="async" data-nimg="fill" class="object-cover select-none" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/globe.svg"/></div><div class="absolute top-0 bottom-0 w-px bg-white/80 dark:bg-white/60 shadow-[0_0_0_1px_rgba(0,0,0,0.2)]" style="left:-0.5px" aria-hidden="true"></div><div role="slider" aria-label="Tree on Beach" aria-valuemin="0" aria-valuemax="0" aria-valuenow="0" tabindex="0" class="absolute top-1/2 -translate-y-1/2 -translate-x-1/2 h-10 w-10 rounded-full bg-white/90 text-zinc-800 dark:text-zinc-900 shadow flex items-center justify-center cursor-ew-resize outline-none ring-0 focus:ring-2 focus:ring-blue-500" style="left:0"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="15 18 9 12 15 6"></polyline></svg><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><polyline points="9 18 15 12 9 6"></polyline></svg></div><figcaption class="absolute bottom-3 right-3 text-sm px-3 py-1 rounded bg-black/60 text-white">Tree on Beach</figcaption></figure></div></div></section><section class="py-16 px-4 bg-gray-100 text-gray-900"><div class="max-w-6xl mx-auto"><div class="flex gap-8"><h2 class="text-3xl font-bold uppercase min-w-fit">Approach</h2><div><p class="text-lg leading-relaxed mb-6">We collect a counterfactual dataset consisting of photos of scenes before and after removing an object, while keeping everything else fixed. We used this dataset to finetune a diffusion model to remove an object and all its effects from the scene. For the task of object insertion, we bootstrap bigger dataset by removing selected objects from a large unsupervised image dataset, resulting in a vast, synthetic counterfactual dataset. Training on this synthetic dataset and then fine tuning on a smaller, original, supervised dataset yields a high quality object insertion model.</p><div class="bg-white rounded-lg p-6 border border-gray-200"><div class="aspect-[2/1] bg-gray-50 rounded flex items-center justify-center text-gray-400"><span class="text-lg">Approach Diagram</span></div></div></div></div></div></section><section class="py-16 px-4 bg-white text-gray-900"><div class="max-w-6xl mx-auto"><div class="flex gap-8"><h2 class="text-3xl font-bold uppercase min-w-fit">BibTex</h2><div class="flex-1"><pre class="bg-gray-50 border border-gray-200 rounded-lg p-6 overflow-x-auto text-sm font-mono">@misc{winter2024objectdrop,
      title={ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion},
      author={Daniel Winter and Matan Cohen and Shlomi Fruchter and Yael Pritch and Alex Rav-Acha and Yedid Hoshen},
      year={2024},
      eprint={2403.18818},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</pre></div></div></div></section><section class="py-16 px-4 bg-gray-200 text-gray-900"><div class="max-w-6xl mx-auto"><div class="flex gap-8"><h2 class="text-3xl font-bold uppercase min-w-fit">Acknowledgment</h2><div class="flex-1"><p class="text-lg leading-relaxed mb-6">We would like to thank to Gitartha Goswami, Soumyadip Ghosh, Reggie Ballesteros, Srimon Chatterjee, Michael Milne and James Adamson for providing the photographs that made this project possible. We thank Yaron Brodsky, Dana Berman, Amir Hertz, Moab Arar, and Oren Katzir for their invaluable feedback and discussions. We also appreciate the insights provided by Dani Lischinski and Daniel Cohen-Or, which helped improve this work.</p><p class="text-lg leading-relaxed">We thank owners of images on this site (<a href="#" class="text-blue-600 hover:underline">link</a> for attributions) for sharing their valuable assets.</p></div></div></div></section></div><!--$--><!--/$--><script src="/_next/static/chunks/708dfc0609e1343f.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n3:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\nc:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/4e7ef18dbe1e50ad.css\",\"style\"]\n:HL[\"/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:T651,"])</script><script>self.__next_f.push([1,"Removing objects from natural images remains a formidable challenge, often hindered by the inability to synthesize semantically appropriate content in the foreground while preserving background integrity. Existing methods often rely on fine-tuning, prompt engineering, or inference-time optimization, yet still struggle to maintain texture consistency, produce rigid or unnatural results, lack precise foreground-background disentanglement, and fail to flexibly handle multiple objectsâ€”ultimately limiting their scalability and practical applicability. In this paper, we propose a zero-shot object removal framework that operates directly on pre-trained text-to-image diffusion modelsâ€”requiring no fine-tuning, no prompts, and no optimization. At the core is our Pixel-wise Attention Dissolution, which performs fine-grained, pixel-wise dissolution of object information by nullifying the most correlated keys for each masked pixel. This operation causes the object to vanish from the self-attention flow, allowing the coherent background context to seamlessly dominate the reconstruction. To complement this, we introduce Localized Attentional Disentanglement Guidance, which steers the denoising process toward latent manifolds that favor clean object removal. Together, Pixel-wise Attention Dissolution and Localized Attentional Disentanglement Guidance enable precise, non-rigid, scalable, and prompt-free multi-object erasure in a single pass. Experiments show our method outperforms state-of-the-art methods even with fine-tuned and prompt-guided baselines in both visual fidelity and semantic plausibility."])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"AArsfQyQ1ehliyZcDM_u1\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/4e7ef18dbe1e50ad.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-slate-700 text-white\",\"children\":[[\"$\",\"section\",null,{\"className\":\"py-12 px-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl md:text-5xl lg:text-6xl font-normal leading-tight mb-8 px-4\",\"children\":[\"PANDORA\",[\"$\",\"br\",null,{}],\"Pixel-wise Attention Dissolution\",[\"$\",\"br\",null,{}],\"and Latent Guidance\",[\"$\",\"br\",null,{}],\"for Zero-Shot Object Removal\"]}],[\"$\",\"div\",null,{\"className\":\"text-lg md:text-xl mb-8\",\"children\":\"Anonymous authors\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center justify-center gap-4 mb-12\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors\",\"children\":\"PDF\"}],[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors\",\"children\":\"ARXIV\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/padora-research/padora-research.github.io\",\"className\":\"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"Code\"}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto bg-gray-100 rounded-lg p-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl text-gray-700 font-light mb-6\",\"children\":\"Demo Video\"}],[\"$\",\"div\",null,{\"className\":\"aspect-video bg-white rounded overflow-hidden\",\"children\":[\"$\",\"video\",null,{\"className\":\"w-full h-full object-cover\",\"controls\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"children\":[[\"$\",\"source\",null,{\"src\":\"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\",\"type\":\"video/mp4\"}],\"Your browser does not support the video tag.\"]}]}]]}]]}]}],[\"$\",\"section\",null,{\"className\":\"py-12 px-4 bg-gray-100 text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold uppercase min-w-fit\",\"children\":\"Abstract\"}],[\"$\",\"p\",null,{\"className\":\"text-lg leading-relaxed\",\"children\":\"$4\"}]]}]}]}],\"$L5\",\"$L6\",\"$L7\",\"$L8\"]}],[\"$L9\"],\"$La\"]}],{},null,false]},null,false],\"$Lb\",false]],\"m\":\"$undefined\",\"G\":[\"$c\",[\"$Ld\"]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[9565,[\"/_next/static/chunks/f7a78c382ccb5d83.js\"],\"default\"]\nf:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"OutletBoundary\"]\n11:I[11533,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"AsyncMetadataOutlet\"]\n13:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"ViewportBoundary\"]\n15:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"MetadataBoundary\"]\n16:\"$Sreact.suspense\"\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"section\",null,{\"className\":\"py-16 px-4 bg-white text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold uppercase text-center mb-6\",\"children\":\"Object Removal\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-center mb-6 max-w-4xl mx-auto leading-relaxed\",\"children\":\"Our object removal model effectively eliminates objects and their effects on the scene from images. Despite being trained on a relatively small counterfactual dataset captured in controlled environments, the model demonstrates remarkable generalization to diverse scenarios, seamlessly removing large objects.\"}],[\"$\",\"div\",null,{\"className\":\"bg-blue-50 border border-blue-200 rounded-lg py-4 px-6 mb-8 text-center\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-blue-900 flex items-center justify-center gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-2xl\",\"children\":\"ðŸ‘†\"}],[\"$\",\"span\",null,{\"children\":\"Click on any image to see results\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-6 mb-12\",\"children\":[[\"$\",\"$Le\",null,{\"beforeSrc\":\"/next.svg\",\"afterSrc\":\"/vercel.svg\",\"label\":\"Boat House\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/window.svg\",\"afterSrc\":\"/globe.svg\",\"label\":\"Hot Air Balloon\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/globe.svg\",\"afterSrc\":\"/file.svg\",\"label\":\"Helicopter\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/vercel.svg\",\"afterSrc\":\"/next.svg\",\"label\":\"Tiger\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/file.svg\",\"afterSrc\":\"/window.svg\",\"label\":\"Dog on Beach\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/next.svg\",\"afterSrc\":\"/vercel.svg\",\"label\":\"Whiskey Glass\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/window.svg\",\"afterSrc\":\"/globe.svg\",\"label\":\"Giraffe\"}],[\"$\",\"$Le\",null,{\"beforeSrc\":\"/globe.svg\",\"afterSrc\":\"/vercel.svg\",\"label\":\"Tree on Beach\"}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"section\",null,{\"className\":\"py-16 px-4 bg-gray-100 text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold uppercase min-w-fit\",\"children\":\"Approach\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg leading-relaxed mb-6\",\"children\":\"We collect a counterfactual dataset consisting of photos of scenes before and after removing an object, while keeping everything else fixed. We used this dataset to finetune a diffusion model to remove an object and all its effects from the scene. For the task of object insertion, we bootstrap bigger dataset by removing selected objects from a large unsupervised image dataset, resulting in a vast, synthetic counterfactual dataset. Training on this synthetic dataset and then fine tuning on a smaller, original, supervised dataset yields a high quality object insertion model.\"}],[\"$\",\"div\",null,{\"className\":\"bg-white rounded-lg p-6 border border-gray-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"aspect-[2/1] bg-gray-50 rounded flex items-center justify-center text-gray-400\",\"children\":[\"$\",\"span\",null,{\"className\":\"text-lg\",\"children\":\"Approach Diagram\"}]}]}]]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"section\",null,{\"className\":\"py-16 px-4 bg-white text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold uppercase min-w-fit\",\"children\":\"BibTex\"}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"pre\",null,{\"className\":\"bg-gray-50 border border-gray-200 rounded-lg p-6 overflow-x-auto text-sm font-mono\",\"children\":\"@misc{winter2024objectdrop,\\n      title={ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion},\\n      author={Daniel Winter and Matan Cohen and Shlomi Fruchter and Yael Pritch and Alex Rav-Acha and Yedid Hoshen},\\n      year={2024},\\n      eprint={2403.18818},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CV}\\n}\"}]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"section\",null,{\"className\":\"py-16 px-4 bg-gray-200 text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold uppercase min-w-fit\",\"children\":\"Acknowledgment\"}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg leading-relaxed mb-6\",\"children\":\"We would like to thank to Gitartha Goswami, Soumyadip Ghosh, Reggie Ballesteros, Srimon Chatterjee, Michael Milne and James Adamson for providing the photographs that made this project possible. We thank Yaron Brodsky, Dana Berman, Amir Hertz, Moab Arar, and Oren Katzir for their invaluable feedback and discussions. We also appreciate the insights provided by Dani Lischinski and Daniel Cohen-Or, which helped improve this work.\"}],[\"$\",\"p\",null,{\"className\":\"text-lg leading-relaxed\",\"children\":[\"We thank owners of images on this site (\",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-blue-600 hover:underline\",\"children\":\"link\"}],\" for attributions) for sharing their valuable assets.\"]}]]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/f7a78c382ccb5d83.js\",\"async\":true,\"nonce\":\"$undefined\"}]\na:[\"$\",\"$Lf\",null,{\"children\":[\"$L10\",[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]]}]\nb:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L15\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$16\",null,{\"fallback\":null,\"children\":\"$L17\"}]}]}]]}]\nd:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/4e7ef18dbe1e50ad.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n10:null\n"])</script><script>self.__next_f.push([1,"18:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"IconMark\"]\n12:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Complete Object Removal via Object-Effect Attention\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"ObjectClear: Complete object removal via object-effect attention with OBER dataset.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L18\",\"3\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"17:\"$12:metadata\"\n"])</script></body></html>